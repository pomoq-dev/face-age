{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OqEP1SlGeVZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SAM: Inference Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE2hzjSNQs0p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content')\n",
    "CODE_DIR = 'face-age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbaMZ40hQxT0",
    "outputId": "f7fac42a-77e7-4b79-ab87-b8805a4b8f39",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pomoq-dev/face-age.git $CODE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43F-3KfeQ08S",
    "outputId": "f1def785-f7aa-4016-c6f7-afc2463d6b06",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
    "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
    "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "av0207x4Q2iL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(f'./{CODE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zvwx9NsiQq9t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from datasets.augmentations import AgeTransformer\n",
    "from utils.common import tensor2im\n",
    "from models.psp import pSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uj3dJjQsQq9y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_TYPE = 'ffhq_aging'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mStxrAtuQq9y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Download Pretrained Model\n",
    "As part of this repository, we provide our pretrained aging model.\n",
    "We'll download the model for the selected experiments as save it to the folder `../pretrained_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pC38oLGQq9z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_download_model_command(file_id, file_name):\n",
    "    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n",
    "    current_directory = os.getcwd()\n",
    "    save_path = os.path.join(os.path.dirname(current_directory), \"pretrained_models\")\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
    "    return url    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOQ2Vz2kQq9z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATHS = {\n",
    "    \"ffhq_aging\": {\"id\": \"1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC\", \"name\": \"sam_ffhq_aging.pt\"}\n",
    "}\n",
    "\n",
    "path = MODEL_PATHS[EXPERIMENT_TYPE]\n",
    "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0nHPvo5Qq9z",
    "outputId": "3ac7ce05-077a-4d81-b6ca-0e5b2dc61753",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget {download_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvRDiRrMQq90",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: Define Inference Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNaSSzZsQq90",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below we have a dictionary defining parameters such as the path to the pretrained model to use and the path to the\n",
    "image to perform inference on.\n",
    "While we provide default values to run this script, feel free to change as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaGqalwuQq90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_DATA_ARGS = {\n",
    "    \"ffhq_aging\": {\n",
    "        \"model_path\": \"../pretrained_models/sam_ffhq_aging.pt\",\n",
    "        \"image_path\": \"notebooks/images/866.jpg\",\n",
    "        \"transform\": transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjkLqLkDQq90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[EXPERIMENT_TYPE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkfqoKJwQq91",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: Load Pretrained Model\n",
    "We assume that you have downloaded the pretrained aging model and placed it in the path defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZuho98JQq91",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_path = EXPERIMENT_ARGS['model_path']\n",
    "ckpt = torch.load(model_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6NOxONxQq91",
    "outputId": "7eecdad5-0678-45d4-d416-898e3fce250d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opts = ckpt['opts']\n",
    "pprint.pprint(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6c93qE9Qq91",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# update the training options\n",
    "opts['checkpoint_path'] = model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRTfKFrkQq91",
    "outputId": "1ebe3ebb-d33f-4764-d88c-8ba0a66ce0a8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opts = Namespace(**opts)\n",
    "net = pSp(opts)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "print('Model successfully loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "!bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/drive/folders/18Z307gsA9zs8oi8VtDGjpyv1ZbsGtYf6?usp=sharing -O images_faces --folder\n",
    "!pip install imageio-ffmpeg\n",
    "\n",
    "from image_converter import convert_images\n",
    "FACES_DIR_PATH = 'images_faces'\n",
    "convert_images(FACES_DIR_PATH)\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images_paths = [EXPERIMENT_DATA_ARGS[EXPERIMENT_TYPE][\"image_path\"]]\n",
    "\n",
    "img_names = os.listdir(FACES_DIR_PATH)\n",
    "images_paths = []\n",
    "for name in img_names:\n",
    "    if '.jpg' in name:\n",
    "        images_paths.append(os.path.join(FACES_DIR_PATH, name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def generate_mp4(out_name, images, kwargs):\n",
    "    writer = imageio.get_writer(out_name + '.mp4', **kwargs)\n",
    "    for image in images:\n",
    "        writer.append_data(image)\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def run_on_batch_to_vecs(inputs, net):\n",
    "    _, result_batch = net(inputs.to(\"cuda\").float(), return_latents=True, randomize_noise=False, resize=False)\n",
    "    return result_batch.cpu()\n",
    "\n",
    "\n",
    "def get_result_from_vecs(vectors_a, vectors_b, alpha):\n",
    "    results = []\n",
    "    for i in range(len(vectors_a)):\n",
    "        cur_vec = vectors_b[i] * alpha + vectors_a[i] * (1 - alpha)\n",
    "        res = net(cur_vec.cuda(), randomize_noise=False, input_code=True, input_is_full=True, resize=False)\n",
    "        results.append(res[0])\n",
    "    return results\n",
    "\n",
    "\n",
    "def show_mp4(filename, width=400):\n",
    "    mp4 = open(filename + '.mp4', 'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    display(HTML(\"\"\"\n",
    "    <video width=\"%d\" controls autoplay loop>\n",
    "        <source src=\"%s\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\" % (width, data_url)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6BegCirQq92",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 4: Visualize Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kc4Sr31TQq92",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "\n",
    "def run_alignment(image_path):\n",
    "    from scripts.align_all_parallel import align_face\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    aligned_image = align_face(filepath=image_path, predictor=predictor)\n",
    "    print(\"Aligned image has shape: {}\".format(aligned_image.size))\n",
    "    return aligned_image\n",
    "\n",
    "\n",
    "def run_on_batch(inputs, net):\n",
    "    result_batch = net(inputs.to(\"cuda\").float(), randomize_noise=False, resize=False)\n",
    "    return result_batch\n",
    "\n",
    "kwargs = {'fps': 40}\n",
    "save_path = \"/content/drive/MyDrive/HOBANA_RESULTS_VIDEOS\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "for ind, image_path in enumerate(images_paths):\n",
    "    try:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        original_image = Image.open(image_path).convert(\"RGB\")\n",
    "        original_image.resize((256, 256))\n",
    "        aligned_image = run_alignment(image_path)\n",
    "        aligned_image.resize((256, 256))\n",
    "\n",
    "        img_transforms = EXPERIMENT_ARGS['transform']\n",
    "        input_image = img_transforms(aligned_image)\n",
    "\n",
    "        # we'll run the image on multiple target ages\n",
    "        target_ages = list(range(1,100))\n",
    "        age_transformers = [AgeTransformer(target_age=age) for age in target_ages]\n",
    "\n",
    "        # for each age transformed age, we'll concatenate the results to display them side-by-side\n",
    "        # results = np.array(aligned_image.resize((1024, 1024)))\n",
    "        res_images_np = []\n",
    "        res_images = []\n",
    "        for age_transformer in age_transformers:\n",
    "            print(f\"Running on target age: {age_transformer.target_age}\")\n",
    "            with torch.no_grad():\n",
    "                input_image_age = [age_transformer(input_image.cpu()).to('cuda')]\n",
    "                input_image_age = torch.stack(input_image_age)\n",
    "                result_tensor = run_on_batch(input_image_age, net)[0]\n",
    "                result_image = tensor2im(result_tensor)\n",
    "                # results = np.concatenate([results, result_image], axis=1)\n",
    "                res_images.append(result_image)\n",
    "                res_images_np.append(np.array(result_image))\n",
    "\n",
    "        # results = Image.fromarray(results)\n",
    "\n",
    "        # save image at full resolution\n",
    "        res_img_name = \"age_transformed_image_{}.jpg\".format(ind)\n",
    "        # results.save('/content/drive/MyDrive/HOBANA_RESULTS_NEW/{}'.format(res_img_name))\n",
    "        for res_img_i, res_img in enumerate(res_images):\n",
    "            res_img.save('/content/drive/MyDrive/HOBANA_RESULTS_NEW/{}_{}'.format(res_img_i, res_img_name))\n",
    "\n",
    "        animation_path = os.path.join(save_path, f\"{image_name}_animation\")\n",
    "        generate_mp4(animation_path, res_images_np, kwargs)\n",
    "        show_mp4(animation_path)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "inference_playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}